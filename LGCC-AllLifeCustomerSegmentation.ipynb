{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllLife Bank Customer Segmentation\n",
    "\n",
    "The Bank is running new marketing campaign for next year. The marketing team suggested to do a customer segmentation to focused those marketing to each customer groups in order to target on new customers as well as existing customers. The Operation teams wants to ensure that customer queries are resolved faster.\n",
    "\n",
    "### Objective\n",
    "Identify different segmentation in the existing customer, based on theri spending patterns as well as past interaction with the bank\n",
    "* Using clustering algoritms\n",
    "* Provide recommendations to the bank on how to better market to and service these customers.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "- How many different types (clusters/segments) of bank customers can be found from the data?\n",
    "- How do these different groups of customer differ from each other?\n",
    "- How to perform clustering using the components obtained from PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "Financial attributes of Bank Customers: credit limit, total number of credit cards, different contact channels\n",
    "\n",
    "**Data Dictionary**\n",
    "- Sl_No: Primary key of the records\n",
    "- Customer Key: Customer identification number\n",
    "- Average Credit Limit: Average credit limit of each customer for all credit cards\n",
    "- Total credit cards: Total number of credit cards possessed by the customer\n",
    "- Total visits bank: Total number of visits that customer made (yearly) personally to the bank\n",
    "- Total visits online: Total number of visits or online logins made by the customer (yearly)\n",
    "- Total calls made: Total number of calls made by the customer to the bank or its customer service department (yearly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 2;\n                var nbb_unformatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n# Import data manipulation libraries\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# to scale the data using z-score\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# to compute distances\\nfrom scipy.spatial.distance import cdist\\n\\n# to perform k-means clustering and compute silhouette scores\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import silhouette_score\\n\\n# to visualize the elbow curve and silhouette scores\\nfrom yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\\n\\n# to compute distances\\nfrom scipy.spatial.distance import pdist\\n\\n# to perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\\nfrom sklearn.cluster import AgglomerativeClustering\\nfrom scipy.cluster.hierarchy import dendrogram, linkage, cophenet\\n\\n# to perform PCA\\nfrom sklearn.decomposition import PCA\";\n                var nbb_formatted_code = \"# this will help in making the Python code more structured automatically (good coding practice)\\n%load_ext nb_black\\n# Import data manipulation libraries\\nimport pandas as pd\\nimport numpy as np\\n\\n# Libraries to help with data visualization\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n\\n# to scale the data using z-score\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# to compute distances\\nfrom scipy.spatial.distance import cdist\\n\\n# to perform k-means clustering and compute silhouette scores\\nfrom sklearn.cluster import KMeans\\nfrom sklearn.metrics import silhouette_score\\n\\n# to visualize the elbow curve and silhouette scores\\nfrom yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\\n\\n# to compute distances\\nfrom scipy.spatial.distance import pdist\\n\\n# to perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\\nfrom sklearn.cluster import AgglomerativeClustering\\nfrom scipy.cluster.hierarchy import dendrogram, linkage, cophenet\\n\\n# to perform PCA\\nfrom sklearn.decomposition import PCA\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this will help in making the Python code more structured automatically (good coding practice)\n",
    "%load_ext nb_black\n",
    "# Import data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Libraries to help with data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# to scale the data using z-score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# to compute distances\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# to perform k-means clustering and compute silhouette scores\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# to visualize the elbow curve and silhouette scores\n",
    "from yellowbrick.cluster import KElbowVisualizer, SilhouetteVisualizer\n",
    "\n",
    "# to compute distances\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# to perform hierarchical clustering, compute cophenetic correlation, and create dendrograms\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, cophenet\n",
    "\n",
    "# to perform PCA\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\n            setTimeout(function() {\n                var nbb_cell_id = 8;\n                var nbb_unformatted_code = \"## Read Data \\n## S1_No can be use as index column\\ndata = pd.read_excel(\\\"CreditCardCustomerData.xlsx\\\", index_col=\\\"Sl_No\\\")\";\n                var nbb_formatted_code = \"## Read Data\\n## S1_No can be use as index column\\ndata = pd.read_excel(\\\"CreditCardCustomerData.xlsx\\\", index_col=\\\"Sl_No\\\")\";\n                var nbb_cells = Jupyter.notebook.get_cells();\n                for (var i = 0; i < nbb_cells.length; ++i) {\n                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n                             nbb_cells[i].set_text(nbb_formatted_code);\n                        }\n                        break;\n                    }\n                }\n            }, 500);\n            ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Read Data \n",
    "## S1_No can be use as index column\n",
    "data = pd.read_excel(\"CreditCardCustomerData.xlsx\", index_col=\"Sl_No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the problem and perform an Exploratory Data Analysis\n",
    "Problem definition, questions to be answered - Data background and contents - Univariate analysis - Bivariate analysis - Insights based on EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing\n",
    "Prepare the data for analysis - Feature engineering - Missing value treatment - Outlier treatment - Duplicate observations check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying K-means Clustering\n",
    "Apply K-means Clustering - Plot the Elbow curve - Check Silhouette Scores - Figure out appropriate number of clusters - Cluster Profiling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Hierarchical Clustering\n",
    "Apply Hierarchical clustering with different linkage methods - Plot dendrograms for each linkage method - Check cophenetic correlation for each linkage method - Figure out appropriate number of clusters - Cluster Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means vs Hierarchical Clustering\n",
    "Compare clusters obtained from K-means and Hierarchical clustering techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actionable Insights & Recommendations\n",
    "Conclude with the key takeaways for the business - What would be your recommendations to the business?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a3e8d87c5cec14335f3b1a538ddb7a51ac547a3f57637c25f2965f3f1cbaa4c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
